# install and load libraries
# install.packages("ggplot2")
# install.packages("Hmisc")
# install.packages("tidyverse")
# install.packages("rstudioapi")
# install.packages("xgboost")
# install.packages("randomForest")
# install.packages("VGAM")
# install.packages("class")
# install.packages("e1071")
# install.packages("caret")
# install.packages("gplots")
# install.packages("MLmetrics")
# install.packages('plsgenomics')
# install.packages("writexl")

libraries <- c("rstudioapi", "Hmisc", "ggplot2", "tidyverse", "randomForest", "xgboost", "VGAM", "class", "e1071", "plsgenomics", "caret", "writexl")
lapply(libraries, library, character.only = TRUE)

set.seed(42)

# set wd and load data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
data <- read.csv("data.csv", sep = ";")
# remove trailing whitespace in rows
data$Production_system <- trimws(data$Production_system)

cross_val <- function(scan_type, data, col_name, model_type, k = 10) {
    df_a <- data.frame(matrix(, nrow = 0, ncol = 6))
    names(df_a) <- c("Scan_Type", "Y_Feature", "Model_Used", "Accuracy", "F1_Score", "Confusion_Matrix")
    acc <- 0
    f1 <- 0
    if (col_name == "Production_system") {
        a <- 8
    } else if (col_name == "Freshness") {
        a <- 2
    }    
    class_labels <- c(1: a)
    conf_mat <- table(Actual = class_labels, Predicted = rev(class_labels))
    flds <- createFolds(as.integer(rownames(data)), k = k, list = TRUE, returnTrain = FALSE)
    x_columns <- colnames(data)
    x_columns <- x_columns[!x_columns %in% c("Sample_number", "Scan_type", "Freshness", "Production_system")]

    for (i in 1: k) {
        other_data <- data[-flds[[i]], ]
        val_data <- data[flds[[i]], ]

        if (model_type == "xgboost") {
            train_x <- as.matrix(other_data[colnames(other_data) %in% x_columns])
            val_x <- as.matrix(val_data[colnames(val_data) %in% x_columns])
            train_y <- as.matrix(other_data[col_name])
            val_y <- as.matrix(val_data[col_name])     
            train_matrix <- xgb.DMatrix(data = train_x, label = train_y)
            val_matrix <- xgb.DMatrix(data = val_x, label = val_y)        
            xgboost_model <- xgb.train(data = train_matrix, nrounds = 10, objective = "multi:softmax", num_class = a + 1)
            pred <- factor(predict(xgboost_model, newdata = val_matrix), levels = 1: a)
            val_y <- factor(val_y, levels = 1: a)

        } else if (model_type == "random_forest") {
            new_x_columns = append(x_columns, col_name)
            other_data <- other_data[, colnames(other_data) %in% new_x_columns]
            val_data <- val_data[, colnames(val_data) %in% new_x_columns]            
            if (col_name == "Production_system") {
                rf_model <- randomForest(Production_system ~ ., data = other_data, ntree = 300, type = "classification")
            } else if (col_name == "Freshness") {
                rf_model <- randomForest(Freshness ~ ., data = other_data, ntree = 2, type = "classification")
            }
            pred <- factor(as.integer(unname(predict(rf_model, val_data, type = "response"))), levels = 1: a)
            val_y <- factor(val_data[, col_name], levels = 1: a)
        
        } else if (model_type == "knn") {
            train_x <- other_data[, colnames(other_data) %in% x_columns]
            val_x <- val_data[, colnames(val_data) %in% x_columns]
            train_y <- other_data[, col_name]
            val_y <- factor(val_data[, col_name], levels = 1: a)
            knn_model <- knn(train = train_x, test = val_x, cl = train_y, k = 9)        
            pred <- factor(knn_model, levels = 1: a)

        } else if (model_type == "svm") {
            new_x_columns = append(x_columns, col_name)
            other_data <- other_data[, colnames(other_data) %in% new_x_columns]
            val_data <- val_data[, colnames(val_data) %in% new_x_columns]
            if (col_name == "Production_system") {
                svm_model <- svm(Production_system ~ ., data = other_data, kernel = "radial")
            } else if (col_name == "Freshness") {
                svm_model <- svm(Freshness ~ ., data = other_data, kernel = "radial")
            }
            pred <- factor(as.integer(unname(predict(svm_model, val_data, decision.values = TRUE))), levels = 1: a)
            val_y <- factor(val_data[, col_name], levels = 1: a)
        
        } else if (model_type == "logistic_regression") {
            new_x_columns = append(x_columns, col_name)
            other_data <- other_data[, colnames(other_data) %in% new_x_columns]
            val_data <- val_data[, colnames(val_data) %in% new_x_columns]
            if (col_name == "Production_system") {
                lr_model <- vglm(Production_system ~ ., data = other_data, family = multinomial)
            } else if (col_name == "Freshness") {
                lr_model <- vglm(Freshness ~ ., data = other_data, family = multinomial)
            }
            pred <- factor(as.integer(unname(max.col(predict(lr_model, val_data, type = "response")))), levels = 1: a)
            val_y <- factor(val_data[, col_name], levels = 1: a)

        } else if (model_type == "plsda") {
            train_x <- other_data[, colnames(other_data) %in% x_columns]
            val_x <- val_data[, colnames(val_data) %in% x_columns]
            train_y <- other_data[, col_name]
            val_y <- factor(val_data[, col_name], levels = 1: a)         
            plsda_model <- pls.lda(train_x, train_y, Xtest = val_x, ncomp = 1: 15, nruncv = 100)
            pred <- factor(plsda_model$predclass, levels = 1: a)
        }

        result <- confusionMatrix(pred, val_y)
        acc <- acc + unname(result$overall["Accuracy"])
        if (col_name == "Production_system") {
            f1 <- f1 + mean(unname(result$byClass[, "F1"]), na.rm = TRUE)
        } else if (col_name == "Freshness") {
            f1 <- f1 + mean(result$byClass["F1"], na.rm = TRUE)
        }
        conf_mat <- conf_mat + result$table
        print("Iteration done")
    }
    mean_acc <- acc / k
    mean_f1 <- f1 / k
    print(c(scan_type, col_name, model_type))
    print("--------------------")
    print("Accuracy: ")
    print(mean_acc)
    print("F1 Score: ")
    print(mean_f1)
    print("Confusion Matrix: ")
    print(conf_mat)
    df_a[nrow(df_a) + 1,] = c(scan_type, col_name, model_type, mean_acc, mean_f1, paste(as.vector(conf_mat), collapse = " "))
    return(df_a)
}

cross_val_training <- function(scan_type) {
    print(scan_type)
    df_b <- data.frame(matrix(, nrow = 0, ncol = 6))
    names(df_b) <- c("Scan_Type", "Y_Feature", "Model_Used", "Accuracy", "F1_Score", "Confusion_Matrix")
    # extract numerical data
    on_meat <- data[data$Scan_type == scan_type, ]

    # Convert to factor Change column name to production_system or Freshness
    on_meat$Production_system <- as.numeric(factor(on_meat$Production_system))
    on_meat$Freshness <- as.numeric(factor(on_meat$Freshness))

    on_meat <- on_meat[complete.cases(on_meat$Production_system, on_meat$Freshness), ]
    
    # split the data
    data_splits <- sample(c(TRUE, FALSE), nrow(on_meat), replace = TRUE, prob = c(0.7, 0.3))
    train_data <- on_meat[data_splits, ]
    test_data <- on_meat[!data_splits, ]

    # standardize the data
    columns <- colnames(train_data)
    columns <- columns[!columns %in% c("Sample_number", "Scan_type", "Freshness", "Production_system")]
    train_data_subset <- train_data[, columns]
    train_data_subset <- scale(train_data_subset)
    train_data[, columns] <- train_data_subset

    # Remove the outliers (Any standardized values larger than 3)
    idx <- which(rowSums(train_data_subset > 3) == 0)
    train_data <- train_data[idx, ]

    # Apply the mean and standard deviation from the training dataset to the testing dataset
    train_mean <- apply(train_data_subset, 2, mean)
    train_sd <- apply(train_data_subset, 2, sd)
    test_data_subset <- test_data[, columns]
    test_data_subset <- as.data.frame(scale(test_data_subset, center = train_mean, scale = train_sd))
    test_data[, columns] <- test_data_subset

    y_lst <- c("Production_system", "Freshness")
    model_lst <- c("xgboost", "random_forest", "knn", "svm", "logistic_regression", "plsda")
    model_lst <- c("logistic_regression")

    for (y in y_lst){
        for (model in model_lst) {
            df_c <- cross_val(scan_type, train_data, y, model)
            df_b <- rbind(df_b, df_c)
        }
    }
    print("------------------------------------------------------------")
    return(df_b)
}

scan_type_lst <- c("OM", "TB", "TP")

# Create empty dataframe
df_result <- data.frame(matrix(, nrow = 0, ncol = 6))
names(df_result) <- c("Scan_Type", "Y_Feature", "Model_Used", "Accuracy", "F1_Score", "Confusion_Matrix")

for (scan_type in scan_type_lst) {
    df_result <- rbind(df_result, cross_val_training(scan_type))
}
write_xlsx(df_result, "model_result.xlsx")